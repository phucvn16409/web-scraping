{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmcUKm1vEVko"
      },
      "source": [
        "<h1> <b> Scraping Data Using API ✍ </b> </h1>\n",
        "<p> Excute with Google Colab </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Iimport Library"
      ],
      "metadata": {
        "id": "EgsIAP-iKQBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZpRjqHgEVkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6616a88b-71d8-46d8-e6f6-b6a47075154e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install xlsxwriter\n",
        "import requests\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Get the url for each job"
      ],
      "metadata": {
        "id": "eK9J4O9SKhuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================= NUMBER OF PAGES TO SCRAPE ==========================\n",
        "pageStart = 1\n",
        "pageEnd = 352\n",
        "\n",
        "# ========================= URL PATTERN FOR EACH PAGE ==========================\n",
        "url = 'https://careerbuilder.vn/search-jobs'\n",
        "headers = {\n",
        "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.43\",\n",
        "    \"Content-Length\": \"84\",\n",
        "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
        "    \"Connection\": \"keep-alive\"\n",
        "}\n",
        "linkJob_completed = []\n",
        "linkJob_error = []\n",
        "\n",
        "# ========================== ITERATE OVER EACH PAGE ============================\n",
        "for page in range(pageStart, pageEnd + 1):\n",
        "    try:\n",
        "        # Generate the payload for the current page\n",
        "        if page <= 9:\n",
        "            payload = {'dataOne': 'a:1:{s:4:\"PAGE\";s:1:\"%d\";}' % page}\n",
        "        elif 10 <= page <= 99:\n",
        "            payload = {'dataOne': 'a:1:{s:4:\"PAGE\";s:2:\"%d\";}' % page}\n",
        "        else:\n",
        "            payload = {'dataOne': 'a:1:{s:4:\"PAGE\";s:3:\"%d\";}' % page}\n",
        "\n",
        "        # Make a request to the website\n",
        "        response = requests.post(\n",
        "            url=url, headers=headers, params=payload, files=payload)\n",
        "        if response.status_code == 200:\n",
        "            # Extract job links\n",
        "            for record in response.json().get('data'):\n",
        "                linkJob_completed.append(record.get('LINK_JOB'))\n",
        "        print('Page %d - Scrape Data is completed' % page)\n",
        "\n",
        "    except:\n",
        "        linkJob_error.append('Page %d - Scrape Data is error' % page)\n",
        "        print('Page %d - Scrape Data is error' % page)\n",
        "\n",
        "df_link = pd.DataFrame(linkJob_completed)\n",
        "df_link.to_excel('linkJob_total.xlsx')"
      ],
      "metadata": {
        "id": "rbF9isVpw8v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Extract information for each job"
      ],
      "metadata": {
        "id": "RQYayGUmL7c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(1, 2):\n",
        "    df_link = pd.read_excel(\n",
        "        f\"/content/drive/MyDrive/Colab-Notebooks/careerbuilder-scarping-usingAPI-linkJob/linkJob{n}.xlsx\")\n",
        "    linkJob_completed = list(df_link['link'])\n",
        "\n",
        "    # ============================ DECLARE VAR =================================\n",
        "    header_job = {\n",
        "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
        "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "        \"Cache-Control\": \"max-age=0\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.43\",\n",
        "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "        'Connection': 'keep-alive'\n",
        "    }\n",
        "\n",
        "    jobIndustries, jobLocation, jobType, jobTitle, jobSalary, jobLevel, jobExperience, jobUpdated, jobLink = [\n",
        "    ], [], [], [], [], [], [], [], []\n",
        "    companyType, companyName, companySize, companyUrl, = [], [], [], []\n",
        "    linkError = []\n",
        "    i = 1\n",
        "\n",
        "    for link in linkJob_completed:\n",
        "        response = requests.get(url=link, headers=header_job)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            try:\n",
        "                # ====================== EXTRACR JOB TITLE ======================\n",
        "                jobTitle_check = soup.find('h1', class_='title').text\n",
        "\n",
        "                jobDetailContent = soup.find(\n",
        "                    'section', class_='job-detail-content')\n",
        "\n",
        "                # ==================== EXTRACR JOB INDUSTRIES ===================\n",
        "                jobSalary_check = jobDetailContent.find(\n",
        "                    'i', class_='fa-usd').parent.next_sibling.next_sibling.text\n",
        "\n",
        "                try:\n",
        "                    jobDetailContent_li = jobDetailContent.find_all('li')\n",
        "                    jobIndustries_check = []\n",
        "                    jobIndustries_select = jobDetailContent_li[1].p.find_all(\n",
        "                        'a')\n",
        "                    if jobIndustries_select:\n",
        "                        jobIndustries_check = [\n",
        "                            elem.text.strip() for elem in jobIndustries_select] + jobIndustries_check\n",
        "                        jobIndustries_check = \" - \".join(jobIndustries_check)\n",
        "                        jobIndustries.append(jobIndustries_check)\n",
        "                    else:\n",
        "                        jobIndustries_select = jobDetailContent_li[2].p.find_all(\n",
        "                            'a')\n",
        "                        jobIndustries_check = [\n",
        "                            elem.text.strip() for elem in jobIndustries_select] + jobIndustries_check\n",
        "                        jobIndustries_check = \" - \".join(jobIndustries_check)\n",
        "                        jobIndustries.append(jobIndustries_check)\n",
        "                except:\n",
        "                    jobIndustries.append(\"noData\")\n",
        "\n",
        "                # ===== EXTRACR JOB SALARY, EXPERIENCE, LEVEL, TYPE, UPDATED ====\n",
        "\n",
        "                try:\n",
        "                    jobExperience.append(jobDetailContent.find(\n",
        "                        'i', class_='fa-briefcase').parent.next_sibling.next_sibling.text.strip())\n",
        "                except:\n",
        "                    jobExperience.append(\"noData\")\n",
        "\n",
        "                try:\n",
        "                    jobLevel.append(jobDetailContent.find(\n",
        "                        'i', class_='mdi-account').parent.next_sibling.next_sibling.text)\n",
        "                except:\n",
        "                    jobLevel.append(\"noData\")\n",
        "\n",
        "                try:\n",
        "                    jobType.append(jobDetailContent.find(\n",
        "                        'em', class_='mdi-briefcase-edit').parent.next_sibling.next_sibling.text)\n",
        "                except:\n",
        "                    jobType.append(\"noData\")\n",
        "\n",
        "                try:\n",
        "                    jobUpdated.append(jobDetailContent.find(\n",
        "                        'em', class_='mdi-update').parent.next_sibling.next_sibling.text)\n",
        "                except:\n",
        "                    jobUpdated.append(\"noData\")\n",
        "\n",
        "                # ============ EXTRACR JOB LOCATION, LINK, TITLE ===============\n",
        "                try:\n",
        "                    jobLocation.append(jobDetailContent.find('a').text)\n",
        "                    jobTitle.append(jobTitle_check)\n",
        "                    jobSalary.append(jobSalary_check)\n",
        "                except:\n",
        "                    jobLocation.append(\"noData\")\n",
        "                    jobTitle.append(\"noData\")\n",
        "                    jobSalary.append(\"noData\")\n",
        "\n",
        "                jobLink.append(link)\n",
        "\n",
        "                # ==================== EXTRACR COMPANY INFO =====================\n",
        "                try:\n",
        "                    companyName_check = soup.find(\n",
        "                        'a', class_='job-company-name').text\n",
        "                    companyName.append(companyName_check)\n",
        "\n",
        "                    companyLink = soup.find(\n",
        "                        'a', class_='job-company-name')['href']\n",
        "                    response2 = requests.post(\n",
        "                        url=companyLink, headers=header_job)\n",
        "                    if response2.status_code == 200:\n",
        "                        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
        "\n",
        "                        # Extract company size from the <span> element\n",
        "                        try:\n",
        "                            size = soup2.find(\n",
        "                                'span', class_='mdi-account-supervisor')\n",
        "                            companySize.append(\n",
        "                                size.parent.text.split(':', 1)[-1].strip())\n",
        "                        except:\n",
        "                            companySize.append(\"noData\")\n",
        "\n",
        "                        # Extract company link from the <span> element\n",
        "                        try:\n",
        "                            link = soup2.find('span', class_='mdi-link')\n",
        "                            companyUrl.append(\n",
        "                                link.parent.text.split(':', 1)[-1].strip())\n",
        "                        except:\n",
        "                            companyUrl.append(\"noData\")\n",
        "\n",
        "                        # Extract company type from the <span> element\n",
        "                        try:\n",
        "                            type_company = soup2.find(\n",
        "                                'span', class_='mdi-gavel')\n",
        "                            companyType.append(\n",
        "                                type_company.parent.text.split(':', 1)[-1].strip())\n",
        "                        except:\n",
        "                            companyType.append(\"noData\")\n",
        "                        print(f'Link {i} is completed')\n",
        "                except:\n",
        "                    companyName.append(\"CarrerBuilder's client\")\n",
        "                    companySize.append(\"noData\")\n",
        "                    companyUrl.append(\"noData\")\n",
        "                    companyType.append(\"noData\")\n",
        "                    print(f'Link {i} is completed')\n",
        "\n",
        "            except:\n",
        "                try:\n",
        "                    # =================== EXTRACR JOB LOCATION ==================\n",
        "                    jobLocation_check = soup.find('p', class_='list-workplace').text\n",
        "\n",
        "                    # =================== EXTRACR JOB INDUSTRIE =================\n",
        "                    jobDetailContent = soup.find('div', class_='content')\n",
        "                    jobDetailContent_td = jobDetailContent.find_all(\n",
        "                        'td', class_='content')\n",
        "                    try:\n",
        "                        jobIndustries_select = jobDetailContent_td[0]\n",
        "                        jobIndustries_check = []\n",
        "                        jobIndustries_check = [\n",
        "                            elem.text.strip() for elem in jobIndustries_select] + jobIndustries_check\n",
        "                        jobIndustries_check = \" \".join(jobIndustries_check)\n",
        "                        jobIndustries.append(jobIndustries_check)\n",
        "                    except:\n",
        "                        jobIndustries.append(\"noData\")\n",
        "\n",
        "                    # == EXTRACR JOB SALARY, EXPERIENCE, LEVEL, TYPE, UPDATED ===\n",
        "                    try:\n",
        "                        jobSalary.append(jobDetailContent_td[1].p.text)\n",
        "                    except:\n",
        "                        jobSalary.append(\"noData\")\n",
        "                    try:\n",
        "                        jobType.append(jobDetailContent_td[2].p.text)\n",
        "                    except:\n",
        "                        jobType.append(\"noData\")\n",
        "                    try:\n",
        "                        jobLevel.append(jobDetailContent_td[3].p.text)\n",
        "                    except:\n",
        "                        jobLevel.append(\"noData\")\n",
        "                    try:\n",
        "                        jobExperience.append(\n",
        "                            jobDetailContent_td[4].p.text.strip())\n",
        "                    except:\n",
        "                        jobExperience.append(\"noData\")\n",
        "                    try:\n",
        "                        jobUpdated.append(jobDetailContent_td[6].p.text)\n",
        "                    except:\n",
        "                        jobUpdated.append(\"noData\")\n",
        "\n",
        "                    # ==================== EXTRACR JOB TITLE ====================\n",
        "                    try:\n",
        "                        jobTitle.append(soup.find('div', class_='title').text)\n",
        "                        jobLocation.append(jobLocation_check)\n",
        "                    except:\n",
        "                        jobTitle.append(\"noData\")\n",
        "                        jobLocation.append(\"noData\")\n",
        "\n",
        "                    jobLink.append(link)\n",
        "\n",
        "                    # ================== EXTRACR COMPANY INFO ===================\n",
        "                    try:\n",
        "                        companyName_check = soup.find(\n",
        "                            'a', class_='company').text\n",
        "                        companyName.append(companyName_check)\n",
        "\n",
        "                        companyLink = soup.find('a', class_='company')['href']\n",
        "                        response2 = requests.post(\n",
        "                            url=companyLink, headers=header_job)\n",
        "                        if response2.status_code == 200:\n",
        "                            soup2 = BeautifulSoup(\n",
        "                                response2.text, 'html.parser')\n",
        "                            try:\n",
        "                                # Extract company size from the <span> element\n",
        "                                infoCompany = soup2.find(\n",
        "                                    'div', class_='cp_basic_info_details')\n",
        "                                infoCompany_li = infoCompany.find_all('li')\n",
        "\n",
        "                                try:\n",
        "                                    companyUrl.append(\n",
        "                                        infoCompany_li[2].text.split(':', 1)[-1].strip())\n",
        "                                except:\n",
        "                                    companyUrl.append(\"noData\")\n",
        "\n",
        "                                infoCompany_li_2_span = infoCompany_li[1].find_all(\n",
        "                                    'span', class_='gr')\n",
        "\n",
        "                                try:\n",
        "                                    companySize.append(\n",
        "                                        infoCompany_li_2_span[0].text.split(':', 1)[-1].strip())\n",
        "                                except:\n",
        "                                    companySize.append(\"noData\")\n",
        "                                try:\n",
        "                                    companyType.append(\n",
        "                                        infoCompany_li_2_span[1].text.split(':', 1)[-1].strip())\n",
        "                                except:\n",
        "                                    companyType.append(\"noData\")\n",
        "\n",
        "                                print(f'Link {i} is completed')\n",
        "\n",
        "                            except:\n",
        "                                # Extract company size from the <span> element\n",
        "                                try:\n",
        "                                    size = soup2.find(\n",
        "                                        'span', class_='mdi-account-supervisor')\n",
        "                                    companySize.append(\n",
        "                                        size.parent.text.split(':', 1)[-1].strip())\n",
        "                                except:\n",
        "                                    companySize.append(\"noData\")\n",
        "\n",
        "                                # Extract company link from the <span> element\n",
        "                                try:\n",
        "                                    link = soup2.find(\n",
        "                                        'span', class_='mdi-link')\n",
        "                                    companyUrl.append(\n",
        "                                        link.parent.text.split(':', 1)[-1].strip())\n",
        "                                except:\n",
        "                                    companyUrl.append(\"noData\")\n",
        "\n",
        "                                # Extract company type from the <span> element\n",
        "                                try:\n",
        "                                    type_company = soup2.find(\n",
        "                                        'span', class_='mdi-gavel')\n",
        "                                    companyType.append(\n",
        "                                        type_company.parent.text.split(':', 1)[-1].strip())\n",
        "                                except:\n",
        "                                    companyType.append(\"noData\")\n",
        "                                print(f'Link {i} is completed')\n",
        "\n",
        "                    except:\n",
        "                        companyName.append(\"CarrerBuilder's client\")\n",
        "                        companySize.append(\"noData\")\n",
        "                        companyUrl.append(\"noData\")\n",
        "                        companyType.append(\"noData\")\n",
        "                        print(f'Link {i} is completed')\n",
        "\n",
        "                except:\n",
        "                    if jobLocation is not None:\n",
        "                        linkError.append(link)\n",
        "                        print(f'Link {i} is ERROR - Not equal')\n",
        "                    else:\n",
        "                        jobSalary.append(\"ERROR - HTML format\")\n",
        "                        jobExperience.append(\"ERROR - HTML format\")\n",
        "                        jobLevel.append(\"ERROR - HTML format\")\n",
        "                        jobType.append(\"ERROR - HTML format\")\n",
        "                        jobUpdated.append(\"ERROR - HTML format\")\n",
        "                        jobTitle.append(\"ERROR - HTML format\")\n",
        "                        jobLocation.append(\"ERROR - HTML format\")\n",
        "                        jobIndustries.append(\"ERROR - HTML format\")\n",
        "                        companyName.append(\"ERROR - HTML format\")\n",
        "                        companySize.append(\"ERROR - HTML format\")\n",
        "                        companyUrl.append(\"ERROR - HTML format\")\n",
        "                        companyType.append(\"ERROR - HTML format\")\n",
        "                        jobLink.append(link)\n",
        "                        print(f'Link {i} is ERROR - Format HTML')\n",
        "\n",
        "        else:\n",
        "            jobSalary.append(\"Link ERROR\")\n",
        "            jobExperience.append(\"Link ERROR\")\n",
        "            jobLevel.append(\"Link ERROR\")\n",
        "            jobType.append(\"Link ERROR\")\n",
        "            jobUpdated.append(\"Link ERROR\")\n",
        "            jobTitle.append(\"Link ERROR\")\n",
        "            jobLocation.append(\"Link ERROR\")\n",
        "            jobIndustries.append(\"Link ERROR\")\n",
        "            companyName.append(\"Link ERROR\")\n",
        "            companySize.append(\"Link ERROR\")\n",
        "            companyUrl.append(\"Link ERROR\")\n",
        "            companyType.append(\"Link ERROR\")\n",
        "            jobLink.append(link)\n",
        "            print(f'Link {i} is ERROR - StatusCode <> 200')\n",
        "        i = i + 1\n",
        "\n",
        "    df = pd.DataFrame(list(zip(companyType, companyName, companySize, companyUrl, jobIndustries, jobLocation, jobType, jobTitle, jobSalary, jobLevel, jobExperience, jobUpdated, jobLink)),\n",
        "                      columns=['companyType', 'companyName', 'companySize', 'companyLink', 'jobIndustries', 'jobLocation', 'jobType', 'jobTitle', 'jobSalary', 'jobLevel', 'jobExperience', 'jobUpdated', 'jobLink'])\n",
        "    df.to_excel(\n",
        "        f'/content/drive/MyDrive/Colab-Notebooks/careerbuilder-scarping-usingAPI-completed/crawlData_CarrerBuilder{n}.xlsx', engine='xlsxwriter')\n",
        "\n",
        "    df2 = pd.DataFrame(linkError)\n",
        "    df2.to_excel(\n",
        "        f'/content/drive/MyDrive/Colab-Notebooks/careerbuilder-scarping-usingAPI-linkError/linkError-crawlData_CarrerBuilder{n}.xlsx', engine='xlsxwriter')\n",
        "\n",
        "    print(f'File linkJob{n} is completed')"
      ],
      "metadata": {
        "id": "xxG-V_YfxZCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6ffb9e-a66d-41b9-a7d6-6216393b79fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Link 1 is completed\n",
            "Link 2 is completed\n",
            "Link 3 is completed\n",
            "Link 4 is completed\n",
            "Link 5 is completed\n",
            "Link 6 is completed\n",
            "Link 7 is completed\n",
            "Link 8 is completed\n",
            "Link 9 is completed\n",
            "Link 10 is completed\n",
            "Link 11 is completed\n",
            "Link 12 is completed\n",
            "Link 13 is completed\n",
            "Link 14 is completed\n",
            "Link 15 is completed\n",
            "Link 16 is completed\n",
            "Link 17 is completed\n",
            "Link 18 is completed\n",
            "Link 19 is completed\n",
            "Link 20 is completed\n",
            "Link 21 is completed\n",
            "Link 22 is completed\n",
            "Link 23 is completed\n",
            "Link 24 is completed\n",
            "Link 25 is completed\n",
            "Link 26 is completed\n",
            "Link 27 is completed\n",
            "Link 28 is completed\n",
            "Link 29 is completed\n",
            "Link 30 is completed\n",
            "Link 31 is completed\n",
            "Link 32 is completed\n",
            "Link 33 is completed\n",
            "Link 34 is completed\n",
            "Link 35 is completed\n",
            "Link 36 is completed\n",
            "Link 37 is completed\n",
            "Link 38 is completed\n",
            "Link 39 is completed\n",
            "Link 40 is completed\n",
            "Link 41 is completed\n",
            "Link 42 is completed\n",
            "Link 43 is completed\n",
            "Link 44 is completed\n",
            "Link 45 is completed\n",
            "Link 46 is completed\n",
            "Link 47 is completed\n",
            "Link 48 is completed\n",
            "Link 49 is completed\n",
            "Link 50 is completed\n",
            "Link 51 is completed\n",
            "Link 52 is completed\n",
            "Link 53 is completed\n",
            "Link 54 is completed\n",
            "Link 55 is completed\n",
            "Link 56 is completed\n",
            "Link 57 is completed\n",
            "Link 58 is completed\n",
            "Link 59 is completed\n",
            "Link 60 is completed\n",
            "Link 61 is completed\n",
            "Link 62 is completed\n",
            "Link 63 is completed\n",
            "Link 64 is completed\n",
            "Link 65 is completed\n",
            "Link 66 is completed\n",
            "Link 67 is completed\n",
            "Link 68 is completed\n",
            "Link 69 is completed\n",
            "Link 70 is completed\n",
            "Link 71 is completed\n",
            "Link 72 is completed\n",
            "Link 73 is completed\n",
            "Link 74 is completed\n",
            "Link 75 is completed\n",
            "Link 76 is completed\n",
            "Link 77 is completed\n",
            "Link 78 is completed\n",
            "Link 79 is completed\n",
            "Link 80 is completed\n",
            "Link 81 is completed\n",
            "Link 82 is completed\n",
            "Link 83 is completed\n",
            "Link 84 is completed\n",
            "Link 85 is completed\n",
            "Link 86 is completed\n",
            "Link 87 is completed\n",
            "Link 88 is completed\n",
            "Link 89 is completed\n",
            "Link 90 is completed\n",
            "Link 91 is completed\n",
            "Link 92 is completed\n",
            "Link 93 is completed\n",
            "Link 94 is completed\n",
            "Link 95 is completed\n",
            "Link 96 is completed\n",
            "Link 97 is completed\n",
            "Link 98 is completed\n",
            "Link 99 is completed\n",
            "Link 100 is completed\n",
            "Link 101 is completed\n",
            "Link 102 is completed\n",
            "Link 103 is completed\n",
            "Link 104 is completed\n",
            "Link 105 is completed\n",
            "Link 106 is completed\n",
            "Link 107 is completed\n",
            "Link 108 is completed\n",
            "Link 109 is completed\n",
            "Link 110 is completed\n",
            "Link 111 is completed\n",
            "Link 112 is completed\n",
            "Link 113 is completed\n",
            "Link 114 is completed\n",
            "Link 115 is completed\n",
            "Link 116 is completed\n",
            "Link 117 is completed\n",
            "Link 118 is completed\n",
            "Link 119 is completed\n",
            "Link 120 is completed\n",
            "Link 121 is completed\n",
            "Link 122 is completed\n",
            "Link 123 is completed\n",
            "Link 124 is completed\n",
            "Link 125 is completed\n",
            "Link 126 is completed\n",
            "Link 127 is completed\n",
            "Link 128 is completed\n",
            "Link 129 is completed\n",
            "Link 130 is completed\n",
            "Link 131 is completed\n",
            "Link 132 is completed\n",
            "Link 133 is completed\n",
            "Link 134 is completed\n",
            "Link 135 is completed\n",
            "Link 136 is completed\n",
            "Link 137 is completed\n",
            "Link 138 is completed\n",
            "Link 139 is completed\n",
            "Link 140 is completed\n",
            "Link 141 is completed\n",
            "Link 142 is completed\n",
            "Link 143 is completed\n",
            "Link 144 is completed\n",
            "Link 145 is completed\n",
            "Link 146 is completed\n",
            "Link 147 is completed\n",
            "Link 148 is completed\n",
            "Link 149 is completed\n",
            "Link 150 is completed\n",
            "Link 151 is completed\n",
            "Link 152 is completed\n",
            "Link 153 is completed\n",
            "Link 154 is completed\n",
            "Link 155 is completed\n",
            "Link 156 is completed\n",
            "Link 157 is completed\n",
            "Link 158 is completed\n",
            "Link 159 is completed\n",
            "Link 160 is completed\n",
            "Link 161 is completed\n",
            "Link 162 is completed\n",
            "Link 163 is completed\n",
            "Link 164 is completed\n",
            "Link 165 is completed\n",
            "Link 166 is completed\n",
            "Link 167 is completed\n",
            "Link 168 is completed\n",
            "Link 169 is completed\n",
            "Link 170 is completed\n",
            "Link 171 is completed\n",
            "Link 172 is completed\n",
            "Link 173 is completed\n",
            "Link 174 is completed\n",
            "Link 175 is completed\n",
            "Link 176 is completed\n",
            "Link 177 is completed\n",
            "Link 178 is completed\n",
            "Link 179 is completed\n",
            "Link 180 is completed\n",
            "Link 181 is completed\n",
            "Link 182 is completed\n",
            "Link 183 is completed\n",
            "Link 184 is completed\n",
            "Link 185 is completed\n",
            "Link 186 is completed\n",
            "Link 187 is completed\n",
            "Link 188 is completed\n",
            "Link 189 is completed\n",
            "Link 190 is completed\n",
            "Link 191 is completed\n",
            "Link 192 is completed\n",
            "Link 193 is completed\n",
            "Link 194 is completed\n",
            "Link 195 is completed\n",
            "Link 196 is completed\n",
            "Link 197 is completed\n",
            "Link 198 is completed\n",
            "Link 199 is completed\n",
            "Link 200 is completed\n",
            "Link 201 is completed\n",
            "Link 202 is completed\n",
            "Link 203 is completed\n",
            "Link 204 is completed\n",
            "Link 205 is completed\n",
            "Link 206 is completed\n",
            "Link 207 is completed\n",
            "Link 208 is completed\n",
            "Link 209 is completed\n",
            "Link 210 is completed\n",
            "Link 211 is completed\n",
            "Link 212 is completed\n",
            "Link 213 is completed\n",
            "Link 214 is completed\n",
            "Link 215 is completed\n",
            "Link 216 is completed\n",
            "Link 217 is completed\n",
            "Link 218 is completed\n",
            "Link 219 is completed\n",
            "Link 220 is completed\n",
            "Link 221 is completed\n",
            "Link 222 is completed\n",
            "Link 223 is completed\n",
            "Link 224 is completed\n",
            "Link 225 is completed\n",
            "Link 226 is completed\n",
            "Link 227 is completed\n",
            "Link 228 is completed\n",
            "Link 229 is completed\n",
            "Link 230 is completed\n",
            "Link 231 is completed\n",
            "Link 232 is completed\n",
            "Link 233 is completed\n",
            "Link 234 is completed\n",
            "Link 235 is completed\n",
            "Link 236 is completed\n",
            "Link 237 is completed\n",
            "Link 238 is completed\n",
            "Link 239 is completed\n",
            "Link 240 is completed\n",
            "Link 241 is completed\n",
            "Link 242 is completed\n",
            "Link 243 is completed\n",
            "Link 244 is completed\n",
            "Link 245 is completed\n",
            "Link 246 is completed\n",
            "Link 247 is completed\n",
            "Link 248 is completed\n",
            "Link 249 is completed\n",
            "Link 250 is completed\n",
            "Link 251 is completed\n",
            "Link 252 is ERROR - Not equal\n",
            "Link 253 is completed\n",
            "Link 254 is completed\n",
            "Link 255 is completed\n",
            "Link 256 is completed\n",
            "Link 257 is completed\n",
            "Link 258 is completed\n",
            "Link 259 is completed\n",
            "Link 260 is completed\n",
            "Link 261 is completed\n",
            "Link 262 is completed\n",
            "Link 263 is completed\n",
            "Link 264 is completed\n",
            "Link 265 is completed\n",
            "Link 266 is completed\n",
            "Link 267 is completed\n",
            "Link 268 is completed\n",
            "Link 269 is completed\n",
            "Link 270 is completed\n",
            "Link 271 is completed\n",
            "Link 272 is completed\n",
            "Link 273 is completed\n",
            "Link 274 is completed\n",
            "Link 275 is completed\n",
            "Link 276 is completed\n",
            "Link 277 is completed\n",
            "Link 278 is completed\n",
            "Link 279 is completed\n",
            "Link 280 is completed\n",
            "Link 281 is completed\n",
            "Link 282 is completed\n",
            "Link 283 is completed\n",
            "Link 284 is completed\n",
            "Link 285 is completed\n",
            "Link 286 is completed\n",
            "Link 287 is completed\n",
            "Link 288 is completed\n",
            "Link 289 is completed\n",
            "Link 290 is completed\n",
            "Link 291 is completed\n",
            "Link 292 is completed\n",
            "Link 293 is completed\n",
            "Link 294 is completed\n",
            "Link 295 is completed\n",
            "Link 296 is completed\n",
            "Link 297 is completed\n",
            "Link 298 is completed\n",
            "Link 299 is completed\n",
            "Link 300 is completed\n",
            "Link 301 is completed\n",
            "Link 302 is completed\n",
            "Link 303 is completed\n",
            "Link 304 is completed\n",
            "Link 305 is completed\n",
            "Link 306 is completed\n",
            "Link 307 is completed\n",
            "Link 308 is completed\n",
            "Link 309 is completed\n",
            "Link 310 is completed\n",
            "Link 311 is completed\n",
            "Link 312 is completed\n",
            "Link 313 is completed\n",
            "Link 314 is completed\n",
            "Link 315 is completed\n",
            "Link 316 is completed\n",
            "Link 317 is completed\n",
            "Link 318 is completed\n",
            "Link 319 is completed\n",
            "Link 320 is ERROR - Not equal\n",
            "Link 321 is completed\n",
            "Link 322 is completed\n",
            "Link 323 is completed\n",
            "Link 324 is completed\n",
            "Link 325 is completed\n",
            "Link 326 is completed\n",
            "Link 327 is completed\n",
            "Link 328 is completed\n",
            "Link 329 is completed\n",
            "Link 330 is completed\n",
            "Link 331 is completed\n",
            "Link 332 is completed\n",
            "Link 333 is completed\n",
            "Link 334 is completed\n",
            "Link 335 is completed\n",
            "Link 336 is completed\n",
            "Link 337 is completed\n",
            "Link 338 is completed\n",
            "Link 339 is completed\n",
            "Link 340 is completed\n",
            "Link 341 is completed\n",
            "Link 342 is completed\n",
            "Link 343 is completed\n",
            "Link 344 is completed\n",
            "Link 345 is completed\n",
            "Link 346 is completed\n",
            "Link 347 is completed\n",
            "Link 348 is completed\n",
            "Link 349 is completed\n",
            "Link 350 is completed\n",
            "Link 351 is completed\n",
            "Link 352 is completed\n",
            "Link 353 is completed\n",
            "Link 354 is completed\n",
            "Link 355 is completed\n",
            "Link 356 is completed\n",
            "Link 357 is completed\n",
            "Link 358 is completed\n",
            "Link 359 is completed\n",
            "Link 360 is completed\n",
            "Link 361 is completed\n",
            "Link 362 is completed\n",
            "Link 363 is completed\n",
            "Link 364 is completed\n",
            "Link 365 is completed\n",
            "Link 366 is completed\n",
            "Link 367 is completed\n",
            "Link 368 is completed\n",
            "Link 369 is completed\n",
            "Link 370 is completed\n",
            "Link 371 is completed\n",
            "Link 372 is completed\n",
            "Link 373 is completed\n",
            "Link 374 is completed\n",
            "Link 375 is completed\n",
            "Link 376 is completed\n",
            "Link 377 is completed\n",
            "Link 378 is completed\n",
            "Link 379 is completed\n",
            "Link 380 is completed\n",
            "Link 381 is completed\n",
            "Link 382 is completed\n",
            "Link 383 is completed\n",
            "Link 384 is completed\n",
            "Link 385 is completed\n",
            "Link 386 is completed\n",
            "Link 387 is completed\n",
            "Link 388 is completed\n",
            "Link 389 is ERROR - Not equal\n",
            "Link 390 is completed\n",
            "Link 391 is completed\n",
            "Link 392 is completed\n",
            "Link 393 is completed\n",
            "Link 394 is completed\n",
            "Link 395 is completed\n",
            "Link 396 is completed\n",
            "Link 397 is completed\n",
            "Link 398 is completed\n",
            "Link 399 is completed\n",
            "Link 400 is completed\n",
            "Link 401 is completed\n",
            "Link 402 is completed\n",
            "Link 403 is completed\n",
            "Link 404 is completed\n",
            "Link 405 is completed\n",
            "Link 406 is completed\n",
            "Link 407 is completed\n",
            "Link 408 is completed\n",
            "Link 409 is completed\n",
            "Link 410 is completed\n",
            "Link 411 is completed\n",
            "Link 412 is completed\n",
            "Link 413 is completed\n",
            "Link 414 is completed\n",
            "Link 415 is completed\n",
            "Link 416 is completed\n",
            "Link 417 is completed\n",
            "Link 418 is completed\n",
            "Link 419 is completed\n",
            "Link 420 is completed\n",
            "Link 421 is completed\n",
            "Link 422 is completed\n",
            "Link 423 is completed\n",
            "Link 424 is completed\n",
            "Link 425 is completed\n",
            "Link 426 is completed\n",
            "Link 427 is completed\n",
            "Link 428 is completed\n",
            "Link 429 is completed\n",
            "Link 430 is completed\n",
            "Link 431 is completed\n",
            "Link 432 is completed\n",
            "Link 433 is completed\n",
            "Link 434 is completed\n",
            "Link 435 is completed\n",
            "Link 436 is completed\n",
            "Link 437 is completed\n",
            "Link 438 is completed\n",
            "Link 439 is completed\n",
            "Link 440 is completed\n",
            "Link 441 is completed\n",
            "Link 442 is completed\n",
            "Link 443 is completed\n",
            "Link 444 is completed\n",
            "Link 445 is completed\n",
            "Link 446 is completed\n",
            "Link 447 is completed\n",
            "Link 448 is completed\n",
            "Link 449 is completed\n",
            "Link 450 is completed\n",
            "Link 451 is ERROR - Not equal\n",
            "Link 452 is completed\n",
            "Link 453 is completed\n",
            "Link 454 is completed\n",
            "Link 455 is completed\n",
            "Link 456 is completed\n",
            "Link 457 is completed\n",
            "Link 458 is completed\n",
            "Link 459 is completed\n",
            "Link 460 is ERROR - Not equal\n",
            "Link 461 is completed\n",
            "Link 462 is completed\n",
            "Link 463 is completed\n",
            "Link 464 is completed\n",
            "Link 465 is completed\n",
            "Link 466 is completed\n",
            "Link 467 is ERROR - Not equal\n",
            "Link 468 is completed\n",
            "Link 469 is completed\n",
            "Link 470 is completed\n",
            "Link 471 is completed\n",
            "Link 472 is completed\n",
            "Link 473 is completed\n",
            "Link 474 is completed\n",
            "Link 475 is completed\n",
            "Link 476 is completed\n",
            "Link 477 is ERROR - Not equal\n",
            "Link 478 is completed\n",
            "Link 479 is completed\n",
            "Link 480 is completed\n",
            "Link 481 is completed\n",
            "Link 482 is completed\n",
            "Link 483 is completed\n",
            "Link 484 is completed\n",
            "Link 485 is completed\n",
            "Link 486 is completed\n",
            "Link 487 is completed\n",
            "Link 488 is completed\n",
            "Link 489 is completed\n",
            "Link 490 is completed\n",
            "Link 491 is completed\n",
            "Link 492 is completed\n",
            "Link 493 is completed\n",
            "Link 494 is completed\n",
            "Link 495 is completed\n",
            "Link 496 is completed\n",
            "Link 497 is completed\n",
            "Link 498 is completed\n",
            "Link 499 is completed\n",
            "Link 500 is completed\n",
            "File linkJob1 is completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linkJob_completed.clear()\n",
        "companyType.clear()\n",
        "companyName.clear()\n",
        "companySize.clear()\n",
        "companyUrl.clear()\n",
        "jobIndustries.clear()\n",
        "jobLocation.clear()\n",
        "jobType.clear()\n",
        "jobTitle.clear()\n",
        "jobSalary.clear()\n",
        "jobLevel.clear()\n",
        "jobExperience.clear()\n",
        "jobUpdated.clear()\n",
        "jobLink.clear()"
      ],
      "metadata": {
        "id": "gMDeeUHCy0p6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}